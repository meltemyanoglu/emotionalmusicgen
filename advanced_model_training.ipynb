{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c69ead41",
   "metadata": {},
   "source": [
    "# Advanced Model Training Pipeline\n",
    "Bu notebook farklı model mimarileri ve loss fonksiyonları ile kapsamlı model eğitimi yapar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b865a92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully!\n",
      "Output directory: advanced_vae_models\n",
      "Using chunk size: 10s\n"
     ]
    }
   ],
   "source": [
    "# Configuration for the training pipeline\n",
    "config = {\n",
    "    \"latent_dir\": \"latent_representations\",\n",
    "    \"output_dir\": \"advanced_vae_models\",\n",
    "    \"chunk_size\": 10,\n",
    "    \"max_samples\": None,  # None = tüm veri\n",
    "    \"run_all_configs\": True,  # Tüm konfigürasyonları çalıştır\n",
    "    \"run_comparison\": True,  # Model karşılaştırması yap\n",
    "    \"run_fine_tuning\": True,  # Fine-tuning yap\n",
    "}\n",
    "\n",
    "# Fine-tuning configuration\n",
    "fine_tune_config = {\n",
    "    \"lr\": 1e-5,  # Düşük learning rate\n",
    "    \"epochs\": 50,  # Daha az epoch\n",
    "    \"freeze_encoder\": False,  # Encoder'ı dondurma\n",
    "    \"freeze_decoder\": False,  # Decoder'ı dondurma\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"Output directory: {config['output_dir']}\")\n",
    "print(f\"Using chunk size: {config['chunk_size']}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90b17604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latent_dir': 'latent_representations',\n",
       " 'output_dir': 'advanced_vae_models',\n",
       " 'chunk_size': 10,\n",
       " 'max_samples': None,\n",
       " 'run_all_configs': True,\n",
       " 'run_comparison': True,\n",
       " 'run_fine_tuning': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17eb8eb",
   "metadata": {},
   "source": [
    "# Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ebe8aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch 2.7.0\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "# Import our advanced training utilities\n",
    "import utils._advanced_training\n",
    "from utils._advanced_training import *\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(f\"Using PyTorch {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f22e77",
   "metadata": {},
   "source": [
    "# Model Configuration Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddcbd12",
   "metadata": {},
   "source": [
    "## Available Model Architectures\n",
    "- **Standard**: Geliştirilmiş standart VAE mimarisi\n",
    "- **Residual**: Residual bağlantılı derin ağ\n",
    "- **Deep**: Daha derin çok katmanlı ağ\n",
    "- **Hierarchical**: Hiyerarşik VAE mimarisi\n",
    "\n",
    "## Available Loss Functions\n",
    "- **beta_vae**: Standard Beta-VAE loss\n",
    "- **annealed**: Linearly annealed KL term\n",
    "- **cyclical**: Cyclical annealing of KL term  \n",
    "- **emotion_weighted**: Emotion-aware weighted loss\n",
    "- **hierarchical**: Hierarchical VAE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68dd108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available pre-configured model templates:\n",
      "==================================================\n",
      "\n",
      "STANDARD_BETA:\n",
      "  Architecture: standard\n",
      "  Hidden dims: [512, 256, 128]\n",
      "  Loss type: beta_vae\n",
      "  Optimizer: adam\n",
      "  Learning rate: 0.0001\n",
      "  Batch size: 64\n",
      "  Epochs: 100\n",
      "\n",
      "DEEP_ANNEALED:\n",
      "  Architecture: deep\n",
      "  Hidden dims: [512, 256, 128]\n",
      "  Loss type: annealed\n",
      "  Optimizer: adamw\n",
      "  Learning rate: 5e-05\n",
      "  Batch size: 32\n",
      "  Epochs: 150\n",
      "\n",
      "RESIDUAL_CYCLICAL:\n",
      "  Architecture: residual\n",
      "  Hidden dims: [768, 384, 192]\n",
      "  Loss type: cyclical\n",
      "  Optimizer: adam\n",
      "  Learning rate: 0.0002\n",
      "  Batch size: 48\n",
      "  Epochs: 120\n",
      "\n",
      "HIERARCHICAL_EMOTION:\n",
      "  Architecture: hierarchical\n",
      "  Hidden dims: [512, 256]\n",
      "  Loss type: emotion_weighted\n",
      "  Optimizer: adam\n",
      "  Learning rate: 0.0001\n",
      "  Batch size: 64\n",
      "  Epochs: 100\n"
     ]
    }
   ],
   "source": [
    "# Show available configurations\n",
    "print(\"Available pre-configured model templates:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for config_name, config in CONFIG_TEMPLATES.items():\n",
    "    model_config = config['model_config']\n",
    "    training_config = config['training_config']\n",
    "    \n",
    "    print(f\"\\n{config_name.upper()}:\")\n",
    "    print(f\"  Architecture: {model_config['architecture']}\")\n",
    "    print(f\"  Hidden dims: {model_config['hidden_dims']}\")\n",
    "    print(f\"  Loss type: {training_config['loss_type']}\")\n",
    "    print(f\"  Optimizer: {training_config['optimizer']}\")\n",
    "    print(f\"  Learning rate: {training_config['lr']}\")\n",
    "    print(f\"  Batch size: {training_config['batch_size']}\")\n",
    "    print(f\"  Epochs: {training_config['epochs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "828eb852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_config': {'latent_dim': 750,\n",
       "  'hidden_dims': [512, 256],\n",
       "  'condition_dim': 2,\n",
       "  'architecture': 'hierarchical',\n",
       "  'dropout_rate': 0.25},\n",
       " 'training_config': {'chunk_size': 10,\n",
       "  'batch_size': 64,\n",
       "  'epochs': 100,\n",
       "  'lr': 0.0001,\n",
       "  'optimizer': 'adam',\n",
       "  'loss_type': 'emotion_weighted',\n",
       "  'beta': 0.8,\n",
       "  'use_scheduler': True,\n",
       "  'grad_clip': False,\n",
       "  'early_stopping_patience': 15}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf7499f",
   "metadata": {},
   "source": [
    "# Single Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d0a8e6",
   "metadata": {},
   "source": [
    "## Train a Single Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f526820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "     -------------------------------------- 139.8/139.8 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting jupyterlab_widgets~=3.0.15\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "     -------------------------------------- 216.6/216.6 kB 4.4 MB/s eta 0:00:00\n",
      "Collecting widgetsnbextension~=4.0.14\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 9.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from ipywidgets) (8.36.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.13.2)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: exceptiongroup in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: decorator in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: colorama in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: stack_data in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: pure-eval in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\personal_services\\teklife dayalı hizmetlerim\\duygusal müzik üretme derin öğrenme projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building jupyterlab assets (production, minimized)\n"
     ]
    }
   ],
   "source": [
    "# Run these command in bash: \n",
    "! pip install ipywidgets --upgrade\n",
    "! jupyter nbextension enable --py widgetsnbextension\n",
    "! jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4069dcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training single model: residual_cyclical\n",
      "Architecture: residual\n",
      "Loss type: cyclical\n",
      "Using device: cpu\n",
      "Loaded a total of 6976 latent representations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756d2d720c394e488ca58276f7b36f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading latent representations:   0%|          | 0/6976 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece631b4c56f4fff9f781e4faa65035c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/120:   0%|          | 0/146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 28\u001b[0m\n\u001b[0;32m     20\u001b[0m single_trainer \u001b[38;5;241m=\u001b[39m AdvancedVAETrainer(\n\u001b[0;32m     21\u001b[0m     model_config\u001b[38;5;241m=\u001b[39msingle_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     22\u001b[0m     training_config\u001b[38;5;241m=\u001b[39msingle_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_config\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     23\u001b[0m     latent_dir\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatent_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     24\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m single_stats \u001b[38;5;241m=\u001b[39m \u001b[43msingle_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingle model training completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msingle_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_loss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\personal_services\\Teklife Dayalı Hizmetlerim\\Duygusal Müzik Üretme Derin Öğrenme Projesi\\proje\\benim_calismalarim\\utils\\_advanced_training.py:508\u001b[0m, in \u001b[0;36mAdvancedVAETrainer.train\u001b[1;34m(self, max_samples)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad_clip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    506\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m--> 508\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    511\u001b[0m epoch_recon_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m recon_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\personal_services\\Teklife Dayalı Hizmetlerim\\Duygusal Müzik Üretme Derin Öğrenme Projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m             )\n\u001b[1;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32md:\\personal_services\\Teklife Dayalı Hizmetlerim\\Duygusal Müzik Üretme Derin Öğrenme Projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages\\torch\\optim\\optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32md:\\personal_services\\Teklife Dayalı Hizmetlerim\\Duygusal Müzik Üretme Derin Öğrenme Projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages\\torch\\optim\\adam.py:246\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    234\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    236\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    237\u001b[0m         group,\n\u001b[0;32m    238\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    243\u001b[0m         state_steps,\n\u001b[0;32m    244\u001b[0m     )\n\u001b[1;32m--> 246\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupled_weight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32md:\\personal_services\\Teklife Dayalı Hizmetlerim\\Duygusal Müzik Üretme Derin Öğrenme Projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages\\torch\\optim\\optimizer.py:147\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\personal_services\\Teklife Dayalı Hizmetlerim\\Duygusal Müzik Üretme Derin Öğrenme Projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages\\torch\\optim\\adam.py:933\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 933\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\personal_services\\Teklife Dayalı Hizmetlerim\\Duygusal Müzik Üretme Derin Öğrenme Projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages\\torch\\optim\\adam.py:525\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[0;32m    523\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 525\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    529\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"latent_dir\": \"latent_representations\",\n",
    "    \"output_dir\": \"advanced_vae_models\",\n",
    "    \"chunk_size\": 10,\n",
    "    \"max_samples\": None,  # None = tüm veri\n",
    "    \"run_all_configs\": True,  # Tüm konfigürasyonları çalıştır\n",
    "    \"run_comparison\": True,  # Model karşılaştırması yap\n",
    "    \"run_fine_tuning\": True,  # Fine-tuning yap\n",
    "}\n",
    "\n",
    "# Train a single model (örnek olarak residual_cyclical)\n",
    "single_config_name = 'residual_cyclical'\n",
    "single_config = CONFIG_TEMPLATES[single_config_name]\n",
    "\n",
    "print(f\"Training single model: {single_config_name}\")\n",
    "print(f\"Architecture: {single_config['model_config']['architecture']}\")\n",
    "print(f\"Loss type: {single_config['training_config']['loss_type']}\")\n",
    "\n",
    "# Create trainer\n",
    "single_trainer = AdvancedVAETrainer(\n",
    "    model_config=single_config['model_config'],\n",
    "    training_config=single_config['training_config'],\n",
    "    latent_dir=data[\"latent_dir\"],\n",
    "    output_dir=data[\"output_dir\"]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "single_stats = single_trainer.train(max_samples=data[\"max_samples\"])\n",
    "\n",
    "print(f\"Single model training completed!\")\n",
    "print(f\"Final loss: {single_stats['total_loss'][-1]:.4f}\")\n",
    "print(f\"Best loss: {min(single_stats['total_loss']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f037fd3",
   "metadata": {},
   "source": [
    "# Multiple Model Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079f8454",
   "metadata": {},
   "source": [
    "## Train All Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bbc94a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive training pipeline...\n",
      "Training 4 different model configurations\n",
      "\n",
      "==================================================\n",
      "Training standard_beta\n",
      "==================================================\n",
      "Using device: cpu\n",
      "Loaded a total of 6976 latent representations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8072d7e6c3844e00bfd26760a9e4941c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading latent representations:   0%|          | 0/6976 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81bdbb3612043c39517950a09ed3890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(CONFIG_TEMPLATES)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m different model configurations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Run the complete training pipeline\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m all_results, comparison_df \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_training_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG_TEMPLATES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatent_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatent_dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining pipeline completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel Performance Summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\personal_services\\Teklife Dayalı Hizmetlerim\\Duygusal Müzik Üretme Derin Öğrenme Projesi\\proje\\benim_calismalarim\\utils\\_advanced_training.py:916\u001b[0m, in \u001b[0;36mcreate_training_pipeline\u001b[1;34m(configs, latent_dir, output_dir, max_samples)\u001b[0m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    909\u001b[0m trainer \u001b[38;5;241m=\u001b[39m AdvancedVAETrainer(\n\u001b[0;32m    910\u001b[0m     model_config\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    911\u001b[0m     training_config\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_config\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    912\u001b[0m     latent_dir\u001b[38;5;241m=\u001b[39mlatent_dir,\n\u001b[0;32m    913\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39moutput_dir\n\u001b[0;32m    914\u001b[0m )\n\u001b[1;32m--> 916\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m results[config_name] \u001b[38;5;241m=\u001b[39m stats\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\personal_services\\Teklife Dayalı Hizmetlerim\\Duygusal Müzik Üretme Derin Öğrenme Projesi\\proje\\benim_calismalarim\\utils\\_advanced_training.py:491\u001b[0m, in \u001b[0;36mAdvancedVAETrainer.train\u001b[1;34m(self, max_samples)\u001b[0m\n\u001b[0;32m    487\u001b[0m epoch_kl_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    489\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 491\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[0;32m    492\u001b[0m     latents \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    493\u001b[0m     conditions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalence\u001b[39m\u001b[38;5;124m'\u001b[39m], batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marousal\u001b[39m\u001b[38;5;124m'\u001b[39m]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32md:\\personal_services\\Teklife Dayalı Hizmetlerim\\Duygusal Müzik Üretme Derin Öğrenme Projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages\\tqdm\\notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32md:\\personal_services\\Teklife Dayalı Hizmetlerim\\Duygusal Müzik Üretme Derin Öğrenme Projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32md:\\personal_services\\Teklife Dayalı Hizmetlerim\\Duygusal Müzik Üretme Derin Öğrenme Projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:493\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\personal_services\\Teklife Dayalı Hizmetlerim\\Duygusal Müzik Üretme Derin Öğrenme Projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:424\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\personal_services\\Teklife Dayalı Hizmetlerim\\Duygusal Müzik Üretme Derin Öğrenme Projesi\\proje\\benim_calismalarim\\myenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1171\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1164\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1171\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if data[\"run_all_configs\"]:\n",
    "    print(\"Starting comprehensive training pipeline...\")\n",
    "    print(f\"Training {len(CONFIG_TEMPLATES)} different model configurations\")\n",
    "    \n",
    "    # Run the complete training pipeline\n",
    "    all_results, comparison_df = create_training_pipeline(\n",
    "        configs=CONFIG_TEMPLATES,\n",
    "        latent_dir=data[\"latent_dir\"],\n",
    "        output_dir=data[\"output_dir\"],\n",
    "        max_samples=data[\"max_samples\"]\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining pipeline completed!\")\n",
    "    print(\"\\nModel Performance Summary:\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"Skipping multiple model training (run_all_configs=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fcd7a4",
   "metadata": {},
   "source": [
    "# Model Comparison and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557be4b1",
   "metadata": {},
   "source": [
    "## Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"run_comparison\"]:\n",
    "    # Create model comparator\n",
    "    comparator = ModelComparator(config[\"output_dir\"])\n",
    "    \n",
    "    # Load and compare all results\n",
    "    comparison_df = comparator.create_comparison_report()\n",
    "    \n",
    "    # Display comparison results\n",
    "    print(\"Model Comparison Results:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"\\nTop 3 Best Performing Models:\")\n",
    "    top_models = comparison_df.head(3)\n",
    "    for idx, row in top_models.iterrows():\n",
    "        print(f\"{idx+1}. {row['Model']}\")\n",
    "        print(f\"   Architecture: {row['Architecture']}\")\n",
    "        print(f\"   Loss Type: {row['Loss Type']}\")\n",
    "        print(f\"   Best Loss: {row['Best Loss']:.6f}\")\n",
    "        print(f\"   Convergence: {row['Convergence Epoch']} epochs\")\n",
    "        print()\n",
    "    \n",
    "    # Show some statistics\n",
    "    print(\"Architecture Performance:\")\n",
    "    arch_performance = comparison_df.groupby('Architecture')['Best Loss'].agg(['mean', 'min', 'count'])\n",
    "    print(arch_performance)\n",
    "    \n",
    "    print(\"\\nLoss Function Performance:\")\n",
    "    loss_performance = comparison_df.groupby('Loss Type')['Best Loss'].agg(['mean', 'min', 'count'])\n",
    "    print(loss_performance)\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping model comparison (run_comparison=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff8277b",
   "metadata": {},
   "source": [
    "# Fine-tuning Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7427a7",
   "metadata": {},
   "source": [
    "## Fine-tune the Best Performing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a275131",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"run_fine_tuning\"]:\n",
    "    # Load comparison results to find best model\n",
    "    comparator = ModelComparator(config[\"output_dir\"])\n",
    "    comparison_df = comparator.create_comparison_report()\n",
    "    \n",
    "    # Get best model\n",
    "    best_model_name = comparison_df.iloc[0]['Model']\n",
    "    best_architecture = comparison_df.iloc[0]['Architecture']\n",
    "    best_loss_type = comparison_df.iloc[0]['Loss Type']\n",
    "    \n",
    "    print(f\"Fine-tuning best model: {best_model_name}\")\n",
    "    print(f\"Architecture: {best_architecture}\")\n",
    "    print(f\"Loss type: {best_loss_type}\")\n",
    "    \n",
    "    # Find the corresponding config\n",
    "    best_config = None\n",
    "    for config_name, config_data in CONFIG_TEMPLATES.items():\n",
    "        if (config_data['model_config']['architecture'] == best_architecture and \n",
    "            config_data['training_config']['loss_type'] == best_loss_type):\n",
    "            best_config = config_data\n",
    "            break\n",
    "    \n",
    "    if best_config:\n",
    "        # Create fine-tuning trainer\n",
    "        fine_tune_trainer = AdvancedVAETrainer(\n",
    "            model_config=best_config['model_config'],\n",
    "            training_config=best_config['training_config'],\n",
    "            latent_dir=config[\"latent_dir\"],\n",
    "            output_dir=os.path.join(config[\"output_dir\"], \"fine_tuned_models\")\n",
    "        )\n",
    "        \n",
    "        # Path to best model\n",
    "        best_model_path = os.path.join(config[\"output_dir\"], best_model_name, \"best_model.pt\")\n",
    "        \n",
    "        if os.path.exists(best_model_path):\n",
    "            print(f\"Loading model from: {best_model_path}\")\n",
    "            \n",
    "            # Fine-tune the model\n",
    "            fine_tune_stats = fine_tune_trainer.fine_tune(\n",
    "                pretrained_model_path=best_model_path,\n",
    "                fine_tune_config=fine_tune_config,\n",
    "                max_samples=config[\"max_samples\"]\n",
    "            )\n",
    "            \n",
    "            print(\"Fine-tuning completed!\")\n",
    "            print(f\"Fine-tuned final loss: {fine_tune_stats['total_loss'][-1]:.4f}\")\n",
    "            print(f\"Original best loss: {comparison_df.iloc[0]['Best Loss']:.4f}\")\n",
    "            \n",
    "            improvement = comparison_df.iloc[0]['Best Loss'] - min(fine_tune_stats['total_loss'])\n",
    "            print(f\"Improvement: {improvement:.6f}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"Best model file not found: {best_model_path}\")\n",
    "    else:\n",
    "        print(\"Could not find matching configuration for best model\")\n",
    "        \n",
    "else:\n",
    "    print(\"Skipping fine-tuning (run_fine_tuning=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304f9bda",
   "metadata": {},
   "source": [
    "# Custom Model Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5d372b",
   "metadata": {},
   "source": [
    "## Create and Train Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c52728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model configuration example\n",
    "custom_model_config = {\n",
    "    'latent_dim': 750,\n",
    "    'hidden_dims': [1024, 512, 256, 128],  # More layers\n",
    "    'condition_dim': 2,\n",
    "    'architecture': 'deep',\n",
    "    'dropout_rate': 0.15  # Lower dropout\n",
    "}\n",
    "\n",
    "custom_training_config = {\n",
    "    'chunk_size': 10,\n",
    "    'batch_size': 32,  # Smaller batch for more updates\n",
    "    'epochs': 80,\n",
    "    'lr': 1e-4,\n",
    "    'optimizer': 'adamw',\n",
    "    'loss_type': 'emotion_weighted',\n",
    "    'beta': 0.7,  # Different beta value\n",
    "    'weight_decay': 0.005,\n",
    "    'use_scheduler': True,\n",
    "    'grad_clip': True,\n",
    "    'early_stopping_patience': 25\n",
    "}\n",
    "\n",
    "print(\"Custom model configuration:\")\n",
    "print(f\"Architecture: {custom_model_config['architecture']}\")\n",
    "print(f\"Hidden dims: {custom_model_config['hidden_dims']}\")\n",
    "print(f\"Loss type: {custom_training_config['loss_type']}\")\n",
    "print(f\"Beta: {custom_training_config['beta']}\")\n",
    "\n",
    "# Train custom model\n",
    "custom_trainer = AdvancedVAETrainer(\n",
    "    model_config=custom_model_config,\n",
    "    training_config=custom_training_config,\n",
    "    latent_dir=config[\"latent_dir\"],\n",
    "    output_dir=os.path.join(config[\"output_dir\"], \"custom_models\")\n",
    ")\n",
    "\n",
    "custom_stats = custom_trainer.train(max_samples=config[\"max_samples\"])\n",
    "\n",
    "print(f\"Custom model training completed!\")\n",
    "print(f\"Final loss: {custom_stats['total_loss'][-1]:.4f}\")\n",
    "print(f\"Best loss: {min(custom_stats['total_loss']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cdda19",
   "metadata": {},
   "source": [
    "# Results Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce25274",
   "metadata": {},
   "source": [
    "## Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bafa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize results from a specific model\n",
    "def visualize_model_results(model_name, output_dir):\n",
    "    \"\"\"Visualize results from a specific model\"\"\"\n",
    "    model_dir = os.path.join(output_dir, model_name)\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        print(f\"Model directory not found: {model_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Load training stats\n",
    "    stats_path = os.path.join(model_dir, 'training_stats.json')\n",
    "    if os.path.exists(stats_path):\n",
    "        with open(stats_path, 'r') as f:\n",
    "            stats = json.load(f)\n",
    "        \n",
    "        epochs = range(1, len(stats['total_loss']) + 1)\n",
    "        \n",
    "        plt.figure(figsize=(20, 12))\n",
    "        \n",
    "        # Total loss\n",
    "        plt.subplot(2, 4, 1)\n",
    "        plt.plot(epochs, stats['total_loss'], 'b-', linewidth=2)\n",
    "        plt.title(f'{model_name}\\nTotal Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Loss components\n",
    "        plt.subplot(2, 4, 2)\n",
    "        plt.plot(epochs, stats['recon_loss'], 'g-', label='Reconstruction', linewidth=2)\n",
    "        plt.plot(epochs, stats['kl_loss'], 'r-', label='KL Divergence', linewidth=2)\n",
    "        plt.title('Loss Components')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Learning rate\n",
    "        plt.subplot(2, 4, 3)\n",
    "        if 'learning_rate' in stats and stats['learning_rate']:\n",
    "            plt.plot(epochs, stats['learning_rate'], 'm-', linewidth=2)\n",
    "            plt.title('Learning Rate')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('LR')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Loss ratio\n",
    "        plt.subplot(2, 4, 4)\n",
    "        ratio = np.array(stats['kl_loss']) / (np.array(stats['recon_loss']) + 1e-8)\n",
    "        plt.plot(epochs, ratio, 'orange', linewidth=2)\n",
    "        plt.title('KL/Reconstruction Ratio')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Ratio')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Log scale losses\n",
    "        plt.subplot(2, 4, 5)\n",
    "        plt.semilogy(epochs, stats['total_loss'], 'b-', linewidth=2)\n",
    "        plt.title('Total Loss (Log Scale)')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Log Loss')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Moving averages\n",
    "        plt.subplot(2, 4, 6)\n",
    "        window = min(10, len(stats['total_loss']) // 4)\n",
    "        if window > 1:\n",
    "            moving_avg = pd.Series(stats['total_loss']).rolling(window=window).mean()\n",
    "            plt.plot(epochs, stats['total_loss'], 'b-', alpha=0.3, label='Original')\n",
    "            plt.plot(epochs, moving_avg, 'b-', linewidth=2, label=f'MA({window})')\n",
    "            plt.title('Smoothed Loss')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Loss histogram\n",
    "        plt.subplot(2, 4, 7)\n",
    "        plt.hist(stats['total_loss'], bins=20, alpha=0.7, color='blue')\n",
    "        plt.title('Loss Distribution')\n",
    "        plt.xlabel('Loss Value')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Convergence analysis\n",
    "        plt.subplot(2, 4, 8)\n",
    "        # Calculate running minimum\n",
    "        running_min = []\n",
    "        current_min = float('inf')\n",
    "        for loss in stats['total_loss']:\n",
    "            if loss < current_min:\n",
    "                current_min = loss\n",
    "            running_min.append(current_min)\n",
    "        \n",
    "        plt.plot(epochs, running_min, 'g-', linewidth=2)\n",
    "        plt.title('Best Loss Over Time')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Best Loss')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(model_dir, 'detailed_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(f\"\\n{model_name} Training Summary:\")\n",
    "        print(f\"  Final Loss: {stats['total_loss'][-1]:.6f}\")\n",
    "        print(f\"  Best Loss: {min(stats['total_loss']):.6f}\")\n",
    "        print(f\"  Best Epoch: {np.argmin(stats['total_loss']) + 1}\")\n",
    "        print(f\"  Total Epochs: {len(stats['total_loss'])}\")\n",
    "        print(f\"  Loss Improvement: {stats['total_loss'][0] - min(stats['total_loss']):.6f}\")\n",
    "        \n",
    "        # Convergence analysis\n",
    "        best_idx = np.argmin(stats['total_loss'])\n",
    "        if best_idx < len(stats['total_loss']) - 10:\n",
    "            print(f\"  Early convergence detected at epoch {best_idx + 1}\")\n",
    "        else:\n",
    "            print(f\"  Model still improving at end of training\")\n",
    "\n",
    "# Visualize results from available models\n",
    "output_dir = config[\"output_dir\"]\n",
    "if os.path.exists(output_dir):\n",
    "    available_models = [d for d in os.listdir(output_dir) \n",
    "                       if os.path.isdir(os.path.join(output_dir, d)) and \n",
    "                       os.path.exists(os.path.join(output_dir, d, 'training_stats.json'))]\n",
    "    \n",
    "    print(f\"Found {len(available_models)} trained models:\")\n",
    "    for i, model in enumerate(available_models):\n",
    "        print(f\"{i+1}. {model}\")\n",
    "    \n",
    "    # Visualize the first available model (or specify one)\n",
    "    if available_models:\n",
    "        model_to_visualize = available_models[0]  # Change index to visualize different model\n",
    "        print(f\"\\nVisualizing results for: {model_to_visualize}\")\n",
    "        visualize_model_results(model_to_visualize, output_dir)\n",
    "else:\n",
    "    print(f\"Output directory not found: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d37330",
   "metadata": {},
   "source": [
    "# Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e5d5d8",
   "metadata": {},
   "source": [
    "## Comprehensive Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14aa2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all available model results for comprehensive analysis\n",
    "def comprehensive_analysis(output_dir):\n",
    "    \"\"\"Perform comprehensive analysis of all trained models\"\"\"\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"Output directory not found: {output_dir}\")\n",
    "        return\n",
    "    \n",
    "    model_summaries = []\n",
    "    all_training_curves = {}\n",
    "    \n",
    "    # Collect data from all models\n",
    "    for model_dir in os.listdir(output_dir):\n",
    "        model_path = os.path.join(output_dir, model_dir)\n",
    "        if os.path.isdir(model_path):\n",
    "            stats_path = os.path.join(model_path, 'training_stats.json')\n",
    "            report_path = os.path.join(model_path, 'training_report.json')\n",
    "            \n",
    "            if os.path.exists(stats_path) and os.path.exists(report_path):\n",
    "                # Load data\n",
    "                with open(stats_path, 'r') as f:\n",
    "                    stats = json.load(f)\n",
    "                with open(report_path, 'r') as f:\n",
    "                    report = json.load(f)\n",
    "                \n",
    "                # Collect summary\n",
    "                summary = {\n",
    "                    'model_name': model_dir,\n",
    "                    'architecture': report['model_config']['architecture'],\n",
    "                    'loss_type': report['training_config']['loss_type'],\n",
    "                    'optimizer': report['training_config']['optimizer'],\n",
    "                    'learning_rate': report['training_config']['lr'],\n",
    "                    'batch_size': report['training_config']['batch_size'],\n",
    "                    'dropout_rate': report['model_config']['dropout_rate'],\n",
    "                    'hidden_dims': report['model_config']['hidden_dims'],\n",
    "                    'final_loss': stats['total_loss'][-1],\n",
    "                    'best_loss': min(stats['total_loss']),\n",
    "                    'convergence_epoch': np.argmin(stats['total_loss']) + 1,\n",
    "                    'total_epochs': len(stats['total_loss']),\n",
    "                    'final_recon_loss': stats['recon_loss'][-1],\n",
    "                    'final_kl_loss': stats['kl_loss'][-1],\n",
    "                    'total_parameters': report['training_summary']['total_parameters']\n",
    "                }\n",
    "                model_summaries.append(summary)\n",
    "                \n",
    "                # Store training curves\n",
    "                all_training_curves[model_dir] = stats\n",
    "    \n",
    "    if not model_summaries:\n",
    "        print(\"No trained models found!\")\n",
    "        return\n",
    "    \n",
    "    # Create comprehensive DataFrame\n",
    "    df = pd.DataFrame(model_summaries)\n",
    "    \n",
    "    # Analysis and visualization\n",
    "    plt.figure(figsize=(25, 20))\n",
    "    \n",
    "    # 1. Best loss by architecture\n",
    "    plt.subplot(3, 4, 1)\n",
    "    arch_performance = df.groupby('architecture')['best_loss'].agg(['mean', 'std', 'min'])\n",
    "    arch_performance['mean'].plot(kind='bar', yerr=arch_performance['std'], capsize=4)\n",
    "    plt.title('Mean Best Loss by Architecture')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Best loss by loss type\n",
    "    plt.subplot(3, 4, 2)\n",
    "    loss_performance = df.groupby('loss_type')['best_loss'].agg(['mean', 'std', 'min'])\n",
    "    loss_performance['mean'].plot(kind='bar', yerr=loss_performance['std'], capsize=4)\n",
    "    plt.title('Mean Best Loss by Loss Type')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Convergence speed by architecture\n",
    "    plt.subplot(3, 4, 3)\n",
    "    conv_performance = df.groupby('architecture')['convergence_epoch'].mean()\n",
    "    conv_performance.plot(kind='bar')\n",
    "    plt.title('Mean Convergence Epoch by Architecture')\n",
    "    plt.ylabel('Epochs')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Parameter count vs performance\n",
    "    plt.subplot(3, 4, 4)\n",
    "    plt.scatter(df['total_parameters'], df['best_loss'], alpha=0.7)\n",
    "    plt.xlabel('Total Parameters')\n",
    "    plt.ylabel('Best Loss')\n",
    "    plt.title('Parameters vs Performance')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Learning rate vs performance\n",
    "    plt.subplot(3, 4, 5)\n",
    "    plt.scatter(df['learning_rate'], df['best_loss'], alpha=0.7)\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.ylabel('Best Loss')\n",
    "    plt.title('Learning Rate vs Performance')\n",
    "    plt.xscale('log')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Batch size vs performance\n",
    "    plt.subplot(3, 4, 6)\n",
    "    batch_performance = df.groupby('batch_size')['best_loss'].mean()\n",
    "    batch_performance.plot(kind='bar')\n",
    "    plt.title('Mean Best Loss by Batch Size')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 7. Training curves comparison (best models from each architecture)\n",
    "    plt.subplot(3, 4, 7)\n",
    "    best_by_arch = df.loc[df.groupby('architecture')['best_loss'].idxmin()]\n",
    "    for _, row in best_by_arch.iterrows():\n",
    "        model_name = row['model_name']\n",
    "        if model_name in all_training_curves:\n",
    "            stats = all_training_curves[model_name]\n",
    "            epochs = range(1, len(stats['total_loss']) + 1)\n",
    "            plt.plot(epochs, stats['total_loss'], label=f\"{row['architecture']}\", linewidth=2)\n",
    "    plt.title('Training Curves (Best per Architecture)')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 8. Loss component analysis\n",
    "    plt.subplot(3, 4, 8)\n",
    "    plt.scatter(df['final_recon_loss'], df['final_kl_loss'], \n",
    "               c=df['best_loss'], cmap='viridis', alpha=0.7)\n",
    "    plt.xlabel('Final Reconstruction Loss')\n",
    "    plt.ylabel('Final KL Loss')\n",
    "    plt.title('Loss Components (colored by total loss)')\n",
    "    plt.colorbar(label='Total Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 9. Dropout rate effect\n",
    "    plt.subplot(3, 4, 9)\n",
    "    dropout_performance = df.groupby('dropout_rate')['best_loss'].mean()\n",
    "    dropout_performance.plot(kind='bar')\n",
    "    plt.title('Mean Best Loss by Dropout Rate')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 10. Training efficiency (best loss / epochs)\n",
    "    plt.subplot(3, 4, 10)\n",
    "    df['efficiency'] = df['best_loss'] / df['convergence_epoch']\n",
    "    efficiency_by_arch = df.groupby('architecture')['efficiency'].mean()\n",
    "    efficiency_by_arch.plot(kind='bar')\n",
    "    plt.title('Training Efficiency by Architecture')\n",
    "    plt.ylabel('Loss / Convergence Epoch')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 11. Optimizer comparison\n",
    "    plt.subplot(3, 4, 11)\n",
    "    opt_performance = df.groupby('optimizer')['best_loss'].agg(['mean', 'std'])\n",
    "    opt_performance['mean'].plot(kind='bar', yerr=opt_performance['std'], capsize=4)\n",
    "    plt.title('Mean Best Loss by Optimizer')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 12. Overall ranking\n",
    "    plt.subplot(3, 4, 12)\n",
    "    top_models = df.nsmallest(6, 'best_loss')\n",
    "    model_names = [name[:15] + '...' if len(name) > 15 else name for name in top_models['model_name']]\n",
    "    plt.barh(range(len(top_models)), top_models['best_loss'])\n",
    "    plt.yticks(range(len(top_models)), model_names)\n",
    "    plt.xlabel('Best Loss')\n",
    "    plt.title('Top 6 Models by Performance')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'comprehensive_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed analysis\n",
    "    print(\"COMPREHENSIVE MODEL ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nTotal models analyzed: {len(df)}\")\n",
    "    print(f\"Best overall loss: {df['best_loss'].min():.6f}\")\n",
    "    print(f\"Worst overall loss: {df['best_loss'].max():.6f}\")\n",
    "    print(f\"Mean loss: {df['best_loss'].mean():.6f}\")\n",
    "    print(f\"Loss std: {df['best_loss'].std():.6f}\")\n",
    "    \n",
    "    print(\"\\nTOP 5 MODELS:\")\n",
    "    top_5 = df.nsmallest(5, 'best_loss')\n",
    "    for i, (_, row) in enumerate(top_5.iterrows()):\n",
    "        print(f\"{i+1}. {row['model_name']}\")\n",
    "        print(f\"   Loss: {row['best_loss']:.6f}\")\n",
    "        print(f\"   Architecture: {row['architecture']}\")\n",
    "        print(f\"   Loss type: {row['loss_type']}\")\n",
    "        print(f\"   Convergence: {row['convergence_epoch']} epochs\")\n",
    "        print()\n",
    "    \n",
    "    print(\"ARCHITECTURE RANKING:\")\n",
    "    arch_ranking = df.groupby('architecture')['best_loss'].agg(['mean', 'min', 'count']).sort_values('mean')\n",
    "    print(arch_ranking)\n",
    "    \n",
    "    print(\"\\nLOSS FUNCTION RANKING:\")\n",
    "    loss_ranking = df.groupby('loss_type')['best_loss'].agg(['mean', 'min', 'count']).sort_values('mean')\n",
    "    print(loss_ranking)\n",
    "    \n",
    "    print(\"\\nOPTIMIZER RANKING:\")\n",
    "    opt_ranking = df.groupby('optimizer')['best_loss'].agg(['mean', 'min', 'count']).sort_values('mean')\n",
    "    print(opt_ranking)\n",
    "    \n",
    "    # Save detailed results\n",
    "    df.to_csv(os.path.join(output_dir, 'detailed_model_analysis.csv'), index=False)\n",
    "    print(f\"\\nDetailed analysis saved to: {os.path.join(output_dir, 'detailed_model_analysis.csv')}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run comprehensive analysis\n",
    "analysis_df = comprehensive_analysis(config[\"output_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d12bcda",
   "metadata": {},
   "source": [
    "# Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8159e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary and recommendations\n",
    "print(\"TRAINING PIPELINE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'analysis_df' in locals() and analysis_df is not None:\n",
    "    best_model = analysis_df.loc[analysis_df['best_loss'].idxmin()]\n",
    "    \n",
    "    print(f\"\\nBEST MODEL OVERALL:\")\n",
    "    print(f\"  Name: {best_model['model_name']}\")\n",
    "    print(f\"  Architecture: {best_model['architecture']}\")\n",
    "    print(f\"  Loss Function: {best_model['loss_type']}\")\n",
    "    print(f\"  Optimizer: {best_model['optimizer']}\")\n",
    "    print(f\"  Best Loss: {best_model['best_loss']:.6f}\")\n",
    "    print(f\"  Parameters: {best_model['total_parameters']:,}\")\n",
    "    print(f\"  Convergence: {best_model['convergence_epoch']} epochs\")\n",
    "    \n",
    "    print(f\"\\nRECOMMENDations:\")\n",
    "    \n",
    "    # Architecture recommendation\n",
    "    best_arch = analysis_df.groupby('architecture')['best_loss'].mean().idxmin()\n",
    "    print(f\"  • Best Architecture: {best_arch}\")\n",
    "    \n",
    "    # Loss function recommendation  \n",
    "    best_loss_type = analysis_df.groupby('loss_type')['best_loss'].mean().idxmin()\n",
    "    print(f\"  • Best Loss Function: {best_loss_type}\")\n",
    "    \n",
    "    # Optimizer recommendation\n",
    "    best_optimizer = analysis_df.groupby('optimizer')['best_loss'].mean().idxmin()\n",
    "    print(f\"  • Best Optimizer: {best_optimizer}\")\n",
    "    \n",
    "    # Learning rate analysis\n",
    "    best_lr_models = analysis_df.nsmallest(3, 'best_loss')\n",
    "    mean_best_lr = best_lr_models['learning_rate'].mean()\n",
    "    print(f\"  • Recommended Learning Rate: {mean_best_lr:.2e}\")\n",
    "    \n",
    "    # Batch size analysis\n",
    "    best_batch_models = analysis_df.nsmallest(3, 'best_loss')\n",
    "    mean_best_batch = int(best_batch_models['batch_size'].mean())\n",
    "    print(f\"  • Recommended Batch Size: {mean_best_batch}\")\n",
    "    \n",
    "    print(f\"\\nNEXT STEPS:\")\n",
    "    print(f\"  • Use {best_model['model_name']} for music generation\")\n",
    "    print(f\"  • Consider fine-tuning with domain-specific data\")\n",
    "    print(f\"  • Experiment with ensemble methods using top 3 models\")\n",
    "    print(f\"  • Implement model compression for deployment\")\n",
    "\n",
    "print(f\"\\nAll models and results saved in: {config['output_dir']}\")\n",
    "print(\"Training pipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d031d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training standard_beta\n",
      "==================================================\n",
      "Using device: cpu\n",
      "Loaded a total of 6976 latent representations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7864ccfd367b44b0916b45de3781f34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading latent representations:   0%|          | 0/6976 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6bf6e43beb435e81ceff41f0139461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 385321.8931, Recon: 385321.7993, KL: 0.1669\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ba03dce7c945ea9756ca10258e661d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 384914.2844, Recon: 384914.1907, KL: 0.1671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643f54cd352c4e509eb6bd86e58d0e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 384776.0903, Recon: 384775.9966, KL: 0.1667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa50eddf6b184979a1a36169f92a2547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 384729.5106, Recon: 384729.4169, KL: 0.1651\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7595680a385c46e5a6bb4c306af90e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 384714.4751, Recon: 384714.3816, KL: 0.1629\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328e61bdee0242e1ae77e851ac8e2b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 384709.7162, Recon: 384709.6253, KL: 0.1596\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cedaf5dfeafa4dbbb78224438f5a072c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 384708.1431, Recon: 384708.0697, KL: 0.1553\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4885782bdcc244358bc8a4186c693758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 384707.6193, Recon: 384707.5565, KL: 0.1480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3992a58d64ee4e61b7da570ac62d1a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 384707.4553, Recon: 384707.3928, KL: 0.1347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ec969d41cb47beb1fa34b1897dfd1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 384707.4025, Recon: 384707.3400, KL: 0.1119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc4b41bb8444182a5bdd1de50126c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 384707.3687, Recon: 384707.3346, KL: 0.0799\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0d303b58d74440b30b1ed02df2015c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 384707.3624, Recon: 384707.3311, KL: 0.0491\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c7203d21f1467a9a8f35bcb633592f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 384707.3406, Recon: 384707.3274, KL: 0.0307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fe8eda98a145e9bb22e79706a62d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 384707.3286, Recon: 384707.3283, KL: 0.0220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fecebae743c74bc6b21faef844f8b15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 384707.3254, Recon: 384707.3254, KL: 0.0175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aacab0e3a95e4c9582f9aed88cb69134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 384707.3283, Recon: 384707.3283, KL: 0.0149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8690506bbdb543e5a8afe638aafe464e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 384707.3260, Recon: 384707.3260, KL: 0.0138\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93aa0e3cff464619a023e9ce4902adeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 384707.3257, Recon: 384707.3257, KL: 0.0129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b12895bd2446c9b23f68df0a3a5068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 384707.3286, Recon: 384707.3286, KL: 0.0122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45cc525fb6754b8a89a255db213bc314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 384707.3306, Recon: 384707.3306, KL: 0.0113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96743e727f64e78b8d4f4f290f1164f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 384707.3240, Recon: 384707.3240, KL: 0.0107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed62a704ed648c085d681ea615bea84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 384707.3265, Recon: 384707.3265, KL: 0.0101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2f672450b148e48f135c9e89782be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 384707.3277, Recon: 384707.3277, KL: 0.0097\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed591cc9b80c449fadf330f628a70f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Loss: 384707.3280, Recon: 384707.3280, KL: 0.0092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015470b8e5a444e4ab9613dc4cb0ca91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 384707.3291, Recon: 384707.3291, KL: 0.0088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e48fcd2072946ca850246ebcb67a188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 384707.3274, Recon: 384707.3274, KL: 0.0085\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145074ee36b44eaa953e12325a3b1912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 384707.3288, Recon: 384707.3288, KL: 0.0080\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ce31a042c64fc68ad56561b9087243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Loss: 384707.3300, Recon: 384707.3300, KL: 0.0079\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406b31faf1cd45e7b07caf193d1f366c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Loss: 384707.3297, Recon: 384707.3297, KL: 0.0079\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b029d2a2c79454c8da432c9df989d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 384707.3303, Recon: 384707.3303, KL: 0.0076\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fabb0d5c77e4c5b8b6aeed4883b62cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Loss: 384707.3268, Recon: 384707.3268, KL: 0.0075\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6faf077376a3419b996822f473d9ef20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Loss: 384707.3277, Recon: 384707.3277, KL: 0.0075\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5f2b95ce624e359def8690baedf8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Loss: 384707.3263, Recon: 384707.3263, KL: 0.0072\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3797765ff53482ba7e60ec3874fb972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Loss: 384707.3220, Recon: 384707.3220, KL: 0.0070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9399729ff54577afba1421e26a17e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Loss: 384707.3257, Recon: 384707.3257, KL: 0.0068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a021a82d4cad43868b8e519c726b035a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Loss: 384707.3234, Recon: 384707.3234, KL: 0.0068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ccb3cdb12c493da4e6ee02f9a15230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Loss: 384707.3257, Recon: 384707.3257, KL: 0.0065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae067615040d491c8f23b674b6d525fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Loss: 384707.3254, Recon: 384707.3254, KL: 0.0064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9461f764877443ea26b425052c75627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Loss: 384707.3263, Recon: 384707.3263, KL: 0.0065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343788a2b07741f4886961ec0b49c21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss: 384707.3277, Recon: 384707.3277, KL: 0.0064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d3f1b5cea8486aac42808a4c3f32b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Loss: 384707.3248, Recon: 384707.3248, KL: 0.0062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca1a4e97638466ba3f8da1e2dc7b2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Loss: 384707.3260, Recon: 384707.3260, KL: 0.0062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca48920d0a104f828bfd094da448bd3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Loss: 384707.3268, Recon: 384707.3268, KL: 0.0061\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c345fdad0bad407abebcda9630eb94d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Loss: 384707.3251, Recon: 384707.3251, KL: 0.0060\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8d11e99bbc4feea2c050e52c12d84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Loss: 384707.3306, Recon: 384707.3306, KL: 0.0059\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513ff9c2201b47ee9f23c83600173ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Loss: 384707.3265, Recon: 384707.3265, KL: 0.0059\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74511966b074fe9bb2f48f8b85e8bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Loss: 384707.3265, Recon: 384707.3265, KL: 0.0057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d54fbe026ff4d5ba8b7a1ecab95b0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Loss: 384707.3286, Recon: 384707.3286, KL: 0.0057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1415fcbfc57d4b7683d1c0ccd3c5dd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Loss: 384707.3271, Recon: 384707.3271, KL: 0.0057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128ad406fb814b958b4549463d255a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 384707.3240, Recon: 384707.3240, KL: 0.0055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56209323cfa4ef8b6a9d5884de86c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 51/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Loss: 384707.3294, Recon: 384707.3294, KL: 0.0055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1544614388348049e4ca85ffaecf3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 52/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Loss: 384707.3243, Recon: 384707.3243, KL: 0.0055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55374c78dff41d696ab2f28cbbad8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 53/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Loss: 384707.3283, Recon: 384707.3283, KL: 0.0054\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77cdcf5d605a4e0eb529c00fc01adf0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 54/100:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Loss: 384707.3228, Recon: 384707.3228, KL: 0.0053\n",
      "Early stopping at epoch 54\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type int64 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Sadece 'standard_beta' config ile model eğit → temiz ve uyumlu model üretiriz\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results, comparison_df \u001b[39m=\u001b[39m create_training_pipeline(\n\u001b[1;32m      3\u001b[0m     configs\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mstandard_beta\u001b[39;49m\u001b[39m'\u001b[39;49m: CONFIG_TEMPLATES[\u001b[39m'\u001b[39;49m\u001b[39mstandard_beta\u001b[39;49m\u001b[39m'\u001b[39;49m]},\n\u001b[1;32m      4\u001b[0m     latent_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlatent_representations\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     output_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39madvanced_vae_models\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     max_samples\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m  \u001b[39m# veya mesela 5000 gibi bir sayı koyabilirsin hızlı deneme için\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/emotional_sound_gen_ver1/utils/_advanced_training.py:916\u001b[0m, in \u001b[0;36mcreate_training_pipeline\u001b[0;34m(configs, latent_dir, output_dir, max_samples)\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m50\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    909\u001b[0m trainer \u001b[39m=\u001b[39m AdvancedVAETrainer(\n\u001b[1;32m    910\u001b[0m     model_config\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mmodel_config\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    911\u001b[0m     training_config\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mtraining_config\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    912\u001b[0m     latent_dir\u001b[39m=\u001b[39mlatent_dir,\n\u001b[1;32m    913\u001b[0m     output_dir\u001b[39m=\u001b[39moutput_dir\n\u001b[1;32m    914\u001b[0m )\n\u001b[0;32m--> 916\u001b[0m stats \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain(max_samples\u001b[39m=\u001b[39;49mmax_samples)\n\u001b[1;32m    917\u001b[0m results[config_name] \u001b[39m=\u001b[39m stats\n\u001b[1;32m    919\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCompleted \u001b[39m\u001b[39m{\u001b[39;00mconfig_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/emotional_sound_gen_ver1/utils/_advanced_training.py:556\u001b[0m, in \u001b[0;36mAdvancedVAETrainer.train\u001b[0;34m(self, max_samples)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_model(\u001b[39m\"\u001b[39m\u001b[39mfinal_model.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    555\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_training_stats(stats)\n\u001b[0;32m--> 556\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_final_report(stats)\n\u001b[1;32m    558\u001b[0m \u001b[39mreturn\u001b[39;00m stats\n",
      "File \u001b[0;32m~/Desktop/emotional_sound_gen_ver1/utils/_advanced_training.py:700\u001b[0m, in \u001b[0;36mAdvancedVAETrainer.create_final_report\u001b[0;34m(self, stats)\u001b[0m\n\u001b[1;32m    681\u001b[0m report \u001b[39m=\u001b[39m {\n\u001b[1;32m    682\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodel_config\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_config,\n\u001b[1;32m    683\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtraining_config\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    696\u001b[0m     }\n\u001b[1;32m    697\u001b[0m }\n\u001b[1;32m    699\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_output_dir, \u001b[39m'\u001b[39m\u001b[39mtraining_report.json\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 700\u001b[0m     json\u001b[39m.\u001b[39;49mdump(report, f, indent\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    702\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining completed. Final loss: \u001b[39m\u001b[39m{\u001b[39;00mstats[\u001b[39m'\u001b[39m\u001b[39mtotal_loss\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    703\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest loss: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mmin\u001b[39m(stats[\u001b[39m'\u001b[39m\u001b[39mtotal_loss\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m at epoch \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39margmin(stats[\u001b[39m'\u001b[39m\u001b[39mtotal_loss\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(skipkeys\u001b[39m=\u001b[39mskipkeys, ensure_ascii\u001b[39m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[39m=\u001b[39mcheck_circular, allow_nan\u001b[39m=\u001b[39mallow_nan, indent\u001b[39m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[39m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[39m=\u001b[39mdefault, sort_keys\u001b[39m=\u001b[39msort_keys, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\u001b[39m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[39m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[39m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/json/encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[39myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    430\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, \u001b[39mdict\u001b[39m):\n\u001b[0;32m--> 431\u001b[0m     \u001b[39myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     \u001b[39mif\u001b[39;00m markers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[39m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[39myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[39mif\u001b[39;00m newline_indent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[39m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[39myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[39mif\u001b[39;00m newline_indent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCircular reference detected\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m     markers[markerid] \u001b[39m=\u001b[39m o\n\u001b[0;32m--> 438\u001b[0m o \u001b[39m=\u001b[39m _default(o)\n\u001b[1;32m    439\u001b[0m \u001b[39myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m markers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type int64 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# Sadece 'standard_beta' config ile model eğit → temiz ve uyumlu model üretiriz\n",
    "results, comparison_df = create_training_pipeline(\n",
    "    configs={'standard_beta': CONFIG_TEMPLATES['standard_beta']},\n",
    "    latent_dir='latent_representations',\n",
    "    output_dir='advanced_vae_models',\n",
    "    max_samples=None  # veya mesela 5000 gibi bir sayı koyabilirsin hızlı deneme için\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
